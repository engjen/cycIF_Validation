{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of CyCIF Optimization\n",
    "\n",
    "**Visualization:** Two-color overlays (DAPI + 1 channel) automatically generated.\n",
    "\n",
    "**Samples:** \n",
    "- Quenching experiments\n",
    "- Round order expeiments\n",
    "- Autofluorescnce Subtraction experiments\n",
    "\n",
    "**Method**: Visualization of images represents a major step in quality control and intrpretation of CyCIF data. The sheer number of images to view presents a challenge, hence the automation of figure generation, herein. Additionally, image data is easily manipulated (contrast/brightness adjustments, ROI selection etc.) so that reproducibility from the raw image data to a publication quality image is nearly impossible with standard tools. Our use of python for visualization makes all of our published figures truly reproducible from the raw images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reviewer comments\n",
    "\n",
    "Define in legend the scale (e.g. scale bar needed) for the tissue images shown throughout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import compress\n",
    "import shutil\n",
    "import skimage\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "os.chdir('/home/groups/graylab_share/OMERO.rdsStore/engje/Data/cmIF')\n",
    "from mplex_image import preprocess, process, analyze, mpimage, cmif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "#important paths\n",
    "os.chdir('/home/groups/graylab_share/OMERO.rdsStore/engje/Data/cycIF_ValidationStudies/cycIF_Validation')\n",
    "codedir = os.getcwd()\n",
    "figdir = f'{codedir}/Figures'\n",
    "figdir = f'/home/groups/graylab_share/OMERO.rdsStore/engje/Data/cycIF_ValidationStudies/Figures'\n",
    "preprocess.cmif_mkdir([figdir])\n",
    "i_micron_per_pixel = .325"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2 a-d: Visualization of quenching\n",
    "\n",
    "Download necessary images from synapse.org\n",
    "\n",
    "syn23644741 https://www.synapse.org/#!Synapse:syn23644741\n",
    "\n",
    "syn23644800 https://www.synapse.org/#!Synapse:syn23644800\n",
    "\n",
    "syn23644827 https://www.synapse.org/#!Synapse:syn23644827"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize quenched images: different H2O2 (4165NPanc), different quanching times (B1640), quenching vs imaging only (NPPan4165)\n",
    "\n",
    "d_process = {\n",
    "    '4165NPanc':f'{codedir}/Images/tiff/4165NPanc/SubtractedRegisteredImages',\n",
    "    'B1640':f'{codedir}/Images/tiff/B1640/', \n",
    "    'NPPan4165':f'{codedir}/Images/tiff/NPPan4165/',\n",
    "    }\n",
    "\n",
    "d_color = {'c1':'DAPI','c2':'AF488','c3':'AF555','c4':'AF647','c5':'AF750'}\n",
    "\n",
    "d_condition = {'4165NPanc-73':['stain 3% H2O2 15min',(2000,9200,308,308)],\n",
    " '4165NPanc-74':['blank 3% H2O2 15min',(2000,9200,308,308)],\n",
    " '4165NPanc-75':['stain 4.5% H2O2 15min',(1800,9000,308,308)],\n",
    " '4165NPanc-76':['blank 4.5% H2O2 15min',(2000,9200,308,308)],\n",
    " '4165NPanc-77':['stain 6% H2O2 15min',(2000,9200,308,308)],\n",
    " '4165NPanc-78':['blank 6% H2O2 15min',(2000,9200,308,308)],\n",
    " 'B1640-T8-3':['blank 3% H2O2 30min ',(6598, 11293, 500, 500)],\n",
    " 'B1640-T8-4':['stain 3% H2O2 60min',(13622, 19711, 500, 500)],\n",
    " 'B1640-T8-5':['stain 3% H2O2 30min',(27667, 19773, 500, 500)], \n",
    " 'B1640-T8-6':['stain 3% H2O2 30min+light',(14181, 19870, 500, 500)],\n",
    " 'NPPan4165-66':['blank no quench',(8000, 8155, 308, 308)],\n",
    " 'NPPan4165-65':['blank 3% H2O2 30min+light',(7924, 9881, 308, 308)],\n",
    " }\n",
    "\n",
    "d_ref = {'3%':'4165NPanc-73',\n",
    "    '4.5%':'4165NPanc-75',\n",
    "    '6%':'4165NPanc-77',\n",
    " }\n",
    "\n",
    "for idx,(s_sample, s_path) in enumerate(d_process.items()):\n",
    "    preprocess.cmif_mkdir([f'{figdir}/{s_sample}/pixel',f'{figdir}/{s_sample}'])\n",
    "    print(s_sample)\n",
    "    df_exp = pd.DataFrame()\n",
    "    #match to czi to tiff names\n",
    "    os.chdir(s_path)\n",
    "    if s_sample == '4165NPanc':\n",
    "        df_img_all = pd.DataFrame()\n",
    "        for s_dir in os.listdir():\n",
    "            os.chdir(s_dir)\n",
    "            df_img = mpimage.parse_org(s_end = \"_ORG.tif\")\n",
    "            df_img.index = [f'{s_dir}/' + item for item in df_img.index]\n",
    "            df_img_all = df_img_all.append(df_img)\n",
    "            os.chdir('..')\n",
    "    else:\n",
    "        df_img_all = mpimage.parse_org(s_end = \"_ORG.tif\")\n",
    "    for s_tissue in sorted(set([item.split('-Scene')[0] for item in df_img_all.scene])):\n",
    "        df =pd.read_csv(f'{codedir}/Metadata/{s_sample}/{s_tissue}_ExposureTimes.csv',index_col=0)\n",
    "        df_exp = df_exp.append(df)\n",
    "    df_img_all['round_int'] = [int(item.split('R')[1]) for item in df_img_all.rounds]\n",
    "    df_img_all['Rounds_of_Quenching'] = df_img_all.round_int - 1\n",
    "    if s_sample == 'NPPan4165':\n",
    "        df_img_all['Rounds_of_Quenching'] = df_img_all.round_int \n",
    "    df_img_all['tissue'] = [item.split('-Scene')[0] for item in df_img_all.scene]\n",
    "    df_img_all = mpimage.add_exposure(df_img_all, df_exp,type='czi')\n",
    "    for s_tissue in sorted(df_img_all.tissue.unique()):\n",
    "        s_tissue_title = d_condition[s_tissue][0]\n",
    "        if s_sample == '4165NPanc':\n",
    "            s_ref_tissue = d_ref[s_tissue_title.split(' ')[1]]\n",
    "            df_ref = df_img_all[df_img_all.tissue==s_ref_tissue]\n",
    "        tu_crop = d_condition[s_tissue][1]\n",
    "        df_img = df_img_all[df_img_all.tissue==s_tissue]\n",
    "        df_dapi = df_img_all[(df_img_all.rounds=='R1') & (df_img_all.color=='c1')& (df_img_all.tissue==s_tissue)]\n",
    "        df_img = df_img[df_img.color != 'c1']\n",
    "        tu_array=(1,2)\n",
    "        i_expnorm=0\n",
    "        for s_color in sorted(set(df_img.color)):\n",
    "            df_img_channel = (df_img[(df_img.color==s_color)&~(df_img.Rounds_of_Quenching.isin(['2','3','4','5','6']))]).sort_values(by='rounds')\n",
    "            s_title = d_color[s_color] + ' ' + s_tissue_title\n",
    "            if s_sample == '4165NPanc':\n",
    "                a_r1 = skimage.io.imread(f'{(df_ref[(df_ref.rounds==\"R1\") & (df_ref.color==s_color)]).index[0]}')\n",
    "                a_crop = a_r1[(tu_crop[1]):(tu_crop[1]+tu_crop[3]),(tu_crop[0]):(tu_crop[0]+tu_crop[2])]\n",
    "                tu_rescale= (0, np.quantile(a_crop,0.98)+np.quantile(a_crop,0.98)/2)\n",
    "            elif s_sample == 'B1640':\n",
    "                tu_rescale = (0, 12000)\n",
    "                i_expnorm=50\n",
    "            else:\n",
    "                tu_rescale = (0,8000)\n",
    "            fig, ax = mpimage.array_roi_if(df_img_channel,df_dapi,s_label='Rounds_of_Quenching',s_title=s_title,tu_crop=tu_crop,\n",
    "                 tu_array=tu_array,tu_fig=(9,4.5),tu_rescale=tu_rescale,i_expnorm=i_expnorm)\n",
    "            fig.savefig(f'{figdir}/{s_sample}/pixel/IFarray_R1stainscaled_{s_tissue}_{s_tissue_title.split(\" \")[1].replace(\"%\",\"\")}_{s_color}_pixelunits.png',dpi=200)\n",
    "            ax[0].set_yticklabels([str(int(int(re.sub(u\"\\u2212\", \"-\", item.get_text()))*i_micron_per_pixel)) for item in ax[0].get_yticklabels(minor=False)])\n",
    "            fig.savefig(f'{figdir}/{s_sample}/IFarray_R1stainscaled_{s_tissue}_{s_tissue_title.split(\" \")[1].replace(\"%\",\"\")}_{s_color}_micronunits.png', dpi=200)\n",
    "            break\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2: Visualization of antibody order\n",
    "\n",
    "Download necessary images from synapse.org\n",
    "\n",
    "syn23644824 https://www.synapse.org/#!Synapse:syn23644824\n",
    "\n",
    "syn23644825 https://www.synapse.org/#!Synapse:syn23644825\n",
    "\n",
    "syn23644826 https://www.synapse.org/#!Synapse:syn23644826"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_process = {\n",
    "    'Her2B-K157':f'{codedir}/Images/tiff/K157/',\n",
    "    'Her2B-K154':f'{codedir}/Images/tiff/K154/',\n",
    "    'Her2B-K175':f'{codedir}/Images/tiff/K175/',\n",
    "    'HER2B-K175':f'{codedir}/Images/tiff/K175/',\n",
    " }\n",
    "\n",
    "d_crop ={'Her2B-K157-Scene-002':(2160,4350,400,400),\n",
    "    'Her2B-K157-Scene-006':(4500,4100,400,400),\n",
    "    'Her2B-K157-Scene-008':(2800,950,400,400),\n",
    "    'Her2B-K154-Scene-002':(3014,3437,400,400),\n",
    "    'Her2B-K154-Scene-006':(4154,4909,400,400),\n",
    "    'Her2B-K154-Scene-008':(3101,1923,400,400),\n",
    "    'HER2B-K175-Scene-02':(3443,3970,400,400),\n",
    "    'HER2B-K175-Scene-06':(2925,4671,400,400),\n",
    "    'HER2B-K175-Scene-08':(4593,4000,400,400),\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#antibody order: double application (K157), original (K154), optimized (K175)\n",
    "\n",
    "for idx,(s_sample, s_path) in enumerate(d_process.items()):\n",
    "    if s_sample == 'HER2B-K175':\n",
    "        pass\n",
    "    preprocess.cmif_mkdir([f'{figdir}/{s_sample}/pixel',f'{figdir}/{s_sample}'])\n",
    "    print(s_sample)\n",
    "    tu_array=(1,1)\n",
    "    tu_fig=(5.5,4.8)\n",
    "    df_exp = pd.DataFrame()\n",
    "    os.chdir(s_path)\n",
    "    #add path info\n",
    "    df_img = mpimage.parse_org()\n",
    "    for s_tissue in sorted(set([item.split('-Scene')[0] for item in df_img.scene])):\n",
    "        df =pd.read_csv(f'{codedir}/Metadata/{s_sample}/{s_tissue}_ExposureTimes.csv',index_col=0)\n",
    "        df_exp = df_exp.append(df)\n",
    "    if s_sample =='Her2B-K154':\n",
    "        df_exp.index = [item.replace('Her2b-K154',s_sample) for item in df_exp.index]\n",
    "        df_img=df_img[df_img.rounds!='R11Q']\n",
    "    df_img['roundfloat'] = df_img.rounds.str.replace('Q','.5')\n",
    "    df_img['_'] = df_img.rounds\n",
    "    df_img['round_int'] = [float(item.split('R')[1]) for item in df_img.roundfloat]\n",
    "    df_img = mpimage.add_exposure(df_img, df_exp,type='czi')\n",
    "\n",
    "    #make arrays\n",
    "    for s_index in df_img.index: \n",
    "        s_marker = df_img.loc[s_index,'marker']\n",
    "        s_scene = df_img.loc[s_index,'scene']\n",
    "        s_round = df_img.loc[s_index,'rounds']\n",
    "        if s_marker == 'DAPI':\n",
    "            continue\n",
    "        df_dapi = df_img[(df_img.scene == s_scene) & (df_img.round_int == 2) & (df_img.color == 'c1')]\n",
    "        df_et = df_img[df_img.index==s_index]\n",
    "        #print(f'{s_marker}  {len(df_et)}')\n",
    "        tu_crop = d_crop[s_scene]\n",
    "        #visualize IF roi\n",
    "        fig, ax = mpimage.array_roi_if(df_et,df_dapi,s_label='_',s_title=s_marker,tu_crop=tu_crop,\n",
    "                tu_array=tu_array,tu_fig=tu_fig,tu_rescale=(0,0),i_expnorm=0)\n",
    "        fig.savefig(f'{figdir}/{s_sample}/pixel/IFarray_{s_scene}_{s_marker}_{s_round}_pixelunits.png')\n",
    "        ax[0].set_yticklabels([str(int(int(re.sub(u\"\\u2212\", \"-\", item.get_text()))*i_micron_per_pixel)) for item in ax[0].get_yticklabels(minor=False)])\n",
    "        fig.savefig(f'{figdir}/{s_sample}/IFarray_{s_scene}_{s_marker}_{s_round}_micronunits.png', dpi=200)\n",
    "        if s_sample == 'Her2B-K157':\n",
    "            if s_round=='R13':\n",
    "                plt.close(fig)\n",
    "        if s_marker != 'CD45':\n",
    "            plt.close(fig)\n",
    "        if s_scene.find('02')== -1:\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ome tiff for napari analysis\n",
    "#ome-tiff parameters\n",
    "import util\n",
    "\n",
    "cropdir=f'{codedir}/Images/Cropped'\n",
    "s_dapi = 'DAPI2'\n",
    "d_combos = {\n",
    "        'Immune':{'CD45','CD8','PD1','CK8'}, #no rep 'CD3',#low bg ,'FoxP3','GRNZB' 'CD20',\n",
    "}\n",
    "\n",
    "for idx,(s_sample, s_path) in enumerate(d_process.items()):\n",
    "    print(s_sample)\n",
    "    df_exp = pd.DataFrame()\n",
    "    os.chdir(s_path)\n",
    "    #add path info\n",
    "    df_img = mpimage.parse_org()\n",
    "    d_replace = dict(zip([item for item in df_img.index if not df_img.loc[item,'marker'] == 'DAPI'],[df_img.loc[item,'rounds'] + '_' + df_img.loc[item,'marker'] for item in df_img.index if not df_img.loc[item,'marker'] == 'DAPI']))\n",
    "    df_img.loc[:,'marker_old']= df_img.loc[:,'marker']\n",
    "    for key, item in d_replace.items():\n",
    "        df_img.loc[key,'marker'] = item\n",
    "    for s_crop_scene,tu_crop_long in d_crop.items():\n",
    "        if s_crop_scene.find(s_sample) > -1:\n",
    "            d_crop_scene = {s_crop_scene: (tu_crop_long[0],tu_crop_long[1])}\n",
    "            d_combos_scene = {'Immune':set(df_img.loc[df_img.marker_old.isin(d_combos['Immune']),'marker'])}\n",
    "            dd_result = mpimage.overlay_crop(d_combos_scene,d_crop_scene,df_img,s_dapi,tu_dim=(2000,2000),b_8bit=True)\n",
    "            util.cropped_ometiff(dd_result,cropdir)\n",
    "    #SKIP crop basins to match cropped overlays\n",
    "    #cmif.load_crop_labels(d_crop,tu_dim,segdir,cropdir,s_find='exp5_CellSegmentationBasins')\n",
    "    #cmif.load_crop_labels(d_crop,tu_dim,segdir,cropdir,s_find='Nuclei Segmentation Basins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for s_crop_scene,tu_crop_long in d_crop.items():\n",
    "        if s_crop_scene.find(s_sample) > -1:\n",
    "            print(s_crop_scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2: Visualization of AF subtraction strategies\n",
    "\n",
    "Download necessary images from synapse.org\n",
    "\n",
    "syn23644795 https://www.synapse.org/#!Synapse:syn23644795\n",
    "\n",
    "syn23644798 https://www.synapse.org/#!Synapse:syn23644798\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AF subtraction r0 or r8Q: note: in paper we generate a scaled image somwhere between R0 and R8Q for subtraction\n",
    "\n",
    "d_process = {\n",
    "    '44290-146_R0':f'{codedir}/Images/tiff/44290-146_R0',\n",
    "    '44290-146_R8Q':f'{codedir}/Images/tiff/44290-146_R8',\n",
    "   }\n",
    "\n",
    "for idx,(s_sample, s_path) in enumerate(d_process.items()):\n",
    "    preprocess.cmif_mkdir([f'{figdir}/{s_sample}/pixel',f'{figdir}/{s_sample}'])\n",
    "    print(s_sample)\n",
    "    tu_array=(1,1)\n",
    "    tu_fig=(5.5,5)\n",
    "    os.chdir(s_path)\n",
    "    #add path info\n",
    "    df_img = mpimage.parse_org()\n",
    "    df_img['_'] =  [item.split('_')[3] for item in df_img.index]\n",
    "    for s_index in df_img.index: \n",
    "        s_marker = df_img.loc[s_index,'marker']\n",
    "        s_scene = df_img.loc[s_index,'scene']\n",
    "        s_round = df_img.loc[s_index,'rounds']\n",
    "        s_sub = df_img.loc[s_index,'_']\n",
    "        tu_rescale=(0,0)\n",
    "        if s_marker == 'DAPI':\n",
    "            continue\n",
    "        elif s_marker == 'R8Qc2':\n",
    "            tu_rescale = (900,7100)\n",
    "        df_dapi = df_img[(df_img.scene == s_scene) & (df_img.rounds == 'R2') & (df_img.color == 'c1')]\n",
    "        df_et = df_img[df_img.index==s_index]\n",
    "        #print(f'{s_marker}  {len(df_et)}')\n",
    "        tu_crop = (2550,10150, 400, 400)\n",
    "        #visualize IF roi\n",
    "        \n",
    "        fig, ax = mpimage.array_roi_if(df_et,df_dapi,s_label='_',s_title=s_marker,tu_crop=tu_crop,\n",
    "            tu_array=tu_array,tu_fig=tu_fig,tu_rescale=tu_rescale,i_expnorm=0)\n",
    "        fig.savefig(f'{figdir}/{s_sample}/pixel/IFarray_{s_sample}_{s_marker}_{s_sub}_pixelunits.png')\n",
    "        ax[0].set_yticklabels([str(int(int(re.sub(u\"\\u2212\", \"-\", item.get_text()))*i_micron_per_pixel)) for item in ax[0].get_yticklabels(minor=False)])\n",
    "        fig.savefig(f'{figdir}/{s_sample}/IFarray_{s_sample}_{s_marker}_{s_sub}_micronunits.png',dpi=200)\n",
    "        if s_marker != 'PCNA':\n",
    "            plt.close(fig)\n",
    "        #visualize IF roi with borders of positive cells after thresholding\n",
    "        os.chdir(f'{s_path}/Borders')\n",
    "        df_border = mpimage.parse_org(type='raw')\n",
    "        df_border.index = './Borders/' + df_border.index\n",
    "        os.chdir(s_path)\n",
    "        if len(set(df_border.marker).intersection(set([s_marker]))) ==1:\n",
    "            fig, ax, a_crop_border = mpimage.roi_if_border(df_et,df_dapi,df_border,s_label='_',s_title=s_marker,tu_crop=tu_crop,tu_array=tu_array,tu_fig=tu_fig,tu_rescale=tu_rescale,i_expnorm=0)\n",
    "            fig.savefig(f'{figdir}/{s_sample}/pixel/IFborder_{s_sample}_{s_marker}_{s_sub}_pixelunits.png')\n",
    "            ax[0].set_yticklabels([str(int(int(re.sub(u\"\\u2212\", \"-\", item.get_text()))*i_micron_per_pixel)) for item in ax[0].get_yticklabels(minor=False)])\n",
    "            fig.savefig(f'{figdir}/{s_sample}/IFborder_{s_sample}_{s_marker}_{s_sub}_micronunits.png',dpi=200)\n",
    "        if s_marker != 'PCNA':\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.9.5",
   "language": "python",
   "name": "python3.9.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
