{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the RESTORE algorithm\n",
    "\n",
    "I ran the RESTORE algorithm with scaling (https://www.biorxiv.org/content/10.1101/2020.09.30.321539v1.full.pdf) on my replicate data to see how well it normalized. \n",
    "\n",
    "The conclusion: \"scaling\" i.e., setting everything below threshold to 0 and scaling everything above threshold between 0.02 and 1 normalizes better than dividing by the threshold, but not as well as other methods (i.e. combat)\n",
    "\n",
    "### Adapted From Single-cell analysis hands-on session\n",
    "Erik Burlingame, Chang Lab, OHSU, 2020-12-2\n",
    "\n",
    "\n",
    "Note: This notebook requires a special python environment and the RESTORE code\n",
    "\n",
    "*please see:*\n",
    "https://gitlab.com/eburling/SCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import os\n",
    "import pandas as pd # dataframe operations\n",
    "import seaborn as sns # clustergram viz\n",
    "import numpy as np # array operations\n",
    "import holoviews as hv # viz\n",
    "import datashader as ds # viz for large data\n",
    "from sklearn.preprocessing import minmax_scale # data scaling\n",
    "from holoviews.operation.datashader import datashade # viz for large data\n",
    "from colorcet import fire, glasbey_hv # perceptually accurate colormaps\n",
    "hv.extension('bokeh') # specify which library for plotting, e.g. 'bokeh' or 'matplotlib'\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../Collaborators')\n",
    "import RESTORE # normalization code, clone Erik's repository https://gitlab.com/eburling/SCA\n",
    "#also follow his instructions for building the rapids environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "#change to correct directory\n",
    "#os.chdir('/home/groups/graylab_share/OMERO.rdsStore/engje/Data/cycIF_ValidationStudies/cycIF_Validation')\n",
    "codedir=os.getcwd()\n",
    "rootdir = f'{codedir}/Data/'\n",
    "datadir = f'{codedir}/Data/filtered_data'\n",
    "os.chdir(datadir)\n",
    "s_type = \"BM-Her2\"#'JE-TMA' \n",
    "#load sampled data\n",
    "if s_type == 'sampled':\n",
    "    s_date = '20201209'\n",
    "    df=pd.read_csv(f'{s_date}_JE-TMA-41-43-62_SampledMeanIntensity_{s_type}.csv',index_col=0)\n",
    "    #df=pd.read_csv(f'{s_date}_BM-Her2N75_SampledMeanIntensity_{s_type}.csv',index_col=0) # for Biomax TMA\n",
    "#or load full data\n",
    "if s_type == \"JE-TMA\":\n",
    "    df=pd.read_csv(f'20201210_JE-TMA-41-43-62_FilteredMeanIntensity.csv',index_col=0)\n",
    "if s_type == \"BM-Her2\":\n",
    "    df=pd.read_csv(f'20201229_BM-Her2N75-15-17-18_MeanIntensity.csv',index_col=0)\n",
    "df['batch'] = [item.split('_')[0] for item in df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_marker_mask = df.dtypes=='float64'\n",
    "raw_marker_cols = df.columns[raw_marker_mask]\n",
    "df['scene'] = [item.split('_cell')[0] for item in df.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate RESTORE thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find mutually exclusive markers by batch\n",
    "i_thresh = 0.66\n",
    "i_low = 0.5\n",
    "d_result = {}\n",
    "d_result_good = {}\n",
    "for QUERY_MARKER in raw_marker_cols:\n",
    "    for QUERY_SCENE in sorted(set(df.batch)):\n",
    "        tissue_mask = (df.batch==QUERY_SCENE)\n",
    "        query_df = df.loc[tissue_mask,raw_marker_cols]\n",
    "        r_vals = []\n",
    "        good_r_vals = []\n",
    "        for marker in query_df:\n",
    "            if marker != QUERY_MARKER:\n",
    "                X = query_df[[QUERY_MARKER, marker]].T\n",
    "                svd =sklearn.decomposition.TruncatedSVD(n_components=2)\n",
    "                svd.fit(X)\n",
    "                r = svd.singular_values_[1] / svd.singular_values_[0]\n",
    "                if r > i_low:\n",
    "                    r_vals.append((marker, r))\n",
    "                if r > i_thresh:\n",
    "                    good_r_vals.append((marker, r))\n",
    "        d_result_good.update({f'{QUERY_MARKER}_{QUERY_SCENE}':(good_r_vals)})\n",
    "        d_result.update({f'{QUERY_MARKER}_{QUERY_SCENE}':(r_vals)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select top r vals\n",
    "d_result_r = {}\n",
    "for QUERY_MARKER in raw_marker_cols:\n",
    "    #print(QUERY_MARKER)\n",
    "    for QUERY_SCENE in sorted(set(df.batch)):\n",
    "        good_r_vals = d_result_good[f'{QUERY_MARKER}_{QUERY_SCENE}']\n",
    "        r_vals = d_result[f'{QUERY_MARKER}_{QUERY_SCENE}']\n",
    "        es_marker = [item[0] for item in good_r_vals]\n",
    "        es_marker_low = [item[0] for item in r_vals]\n",
    "        if len(es_marker) == 0:\n",
    "            d_result_r.update({f'{QUERY_MARKER}_{QUERY_SCENE}':es_marker_low})\n",
    "        else:\n",
    "            d_result_r.update({f'{QUERY_MARKER}_{QUERY_SCENE}':es_marker})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find median threshold of r vals above 0.66, or 0.5 if none above 0.66\n",
    "df_result = pd.DataFrame(index=raw_marker_cols,columns=sorted(set(df.batch)))\n",
    "for key, items in d_result_r.items():\n",
    "    if s_type == \"JE-TMA\":\n",
    "        QUERY_MARKER = key.split('_JE')[0]\n",
    "        QUERY_SCENE = 'JE' + key.split('_JE')[1]\n",
    "    elif s_type == \"BM-Her2\":\n",
    "        QUERY_MARKER = key.split('_BM')[0]\n",
    "        QUERY_SCENE = 'BM' + key.split('_BM')[1]\n",
    "    tissue_mask = (df.batch==QUERY_SCENE)\n",
    "    query_df = df.loc[tissue_mask,raw_marker_cols]\n",
    "    a_norm = np.array([])\n",
    "    for BG_MARKER in items:\n",
    "        X = RESTORE.process_data(query_df[[QUERY_MARKER, BG_MARKER]], \n",
    "                        QUERY_MARKER, BG_MARKER)\n",
    "        norm_factor, clusters = RESTORE.get_ssc_thresh(X)\n",
    "        a_norm = np.append(a_norm,norm_factor)\n",
    "    df_result.loc[QUERY_MARKER,QUERY_SCENE] = np.median(a_norm)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save restore normalization factors\n",
    "if s_type == \"JE-TMA\":\n",
    "    if not os.path.exists('20201229_JE-TMA-41-43-62_restore_normfactor.csv'):\n",
    "        df_result.dropna().to_csv('20201229_JE-TMA-41-43-62_restore_normfactor.csv')\n",
    "elif s_type == \"BM-Her2\":\n",
    "    if not os.path.exists('20201229_BM-Her2N75-15-17-18_restore_normfactor.csv'):\n",
    "        df_result.dropna().to_csv('20201229_BM-Her2N75-15-17-18_restore_normfactor.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply RESTORE normalization: original\n",
    "\n",
    "As we infer background signal based on the negative control, we can scale intensity values by the inferred background signal level of the negative control for individual sample, respectively, to align intensity distribution.(https://doi.org/10.1038/s42003-020-0828-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load saved normalization factors\n",
    "if s_type == \"JE-TMA\":\n",
    "    df_result = pd.read_csv('20201229_JE-TMA-41-43-62_restore_normfactor.csv',index_col=0)\n",
    "elif s_type == \"BM-Her2\":\n",
    "    df_result = pd.read_csv('20201229_BM-Her2N75-15-17-18_restore_normfactor.csv',index_col=0)\n",
    "# apply normalization: division\n",
    "df_norm = pd.DataFrame(index=df.index)\n",
    "for QUERY_MARKER in df_result.dropna().index.tolist():\n",
    "    for QUERY_SCENE in sorted(set(df.batch)):\n",
    "        ls_index = df[df.batch==QUERY_SCENE].index\n",
    "        i_min = df.loc[ls_index,QUERY_MARKER].min()\n",
    "        i_thresh = df_result.loc[QUERY_MARKER,QUERY_SCENE]\n",
    "        df_norm.loc[ls_index,QUERY_MARKER] = (df.loc[ls_index,QUERY_MARKER] - i_min)/(i_thresh - i_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm['batch'] = [item.split('_')[0] for item in df_norm.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for Kbet\n",
    "#save the 3 normalized, sampled dataframes for kbet analysis\n",
    "s_trans='raw'\n",
    "s_date = '20201209'\n",
    "if s_type == \"JE-TMA\":\n",
    "    df_sample=pd.read_csv(f'{s_date}_JE-TMA-41-43-62_SampledMeanIntensity_{s_trans}.csv',index_col=0)\n",
    "elif s_type == \"BM-Her2\":\n",
    "    df_sample=pd.read_csv(f'{s_date}_BM-Her2N75_SampledMeanIntensity_{s_trans}.csv',index_col=0) # for Biomax TMA\n",
    "#save for kbet\n",
    "if s_type == \"JE-TMA\":\n",
    "    df_norm.loc[df_sample.index,:].to_csv(f'{s_date}_JE-TMA-41-43-62_SampledMeanIntensity_restore_div.csv')\n",
    "elif s_type == \"BM-Her2\":\n",
    "    df_norm.loc[df_sample[~df_sample.index.str.contains('cell0000')].index,:].to_csv(f'{s_date}_BM-Her2N75_SampledMeanIntensity_restore_div.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process with arcsinh \n",
    "# remove outliers\n",
    "X = df_norm.loc[:,df_norm.dtypes=='float64']\n",
    "X = X.clip(upper=X.quantile(q=.999),axis=1)\n",
    "\n",
    "# deskew\n",
    "X = (X/5).apply(np.arcsinh)\n",
    "\n",
    "# scale\n",
    "X = X.apply(minmax_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['batch'] = [item.split('_')[0] for item in X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for Kbet\n",
    "#save the 3 normalized, sampled dataframes for kbet analysis\n",
    "s_trans='raw'\n",
    "s_date = '20201209'\n",
    "if s_type == \"JE-TMA\":\n",
    "    df_sample=pd.read_csv(f'{s_date}_JE-TMA-41-43-62_SampledMeanIntensity_{s_trans}.csv',index_col=0)\n",
    "elif s_type == \"BM-Her2\":\n",
    "    df_sample=pd.read_csv(f'{s_date}_BM-Her2N75_SampledMeanIntensity_{s_trans}.csv',index_col=0) # for Biomax TMA\n",
    "#save for kbet\n",
    "if s_type == \"JE-TMA\":\n",
    "    X.loc[df_sample.index,:].to_csv(f'{s_date}_JE-TMA-41-43-62_SampledMeanIntensity_restore_div_arcsinh.csv')\n",
    "elif s_type == \"BM-Her2\":\n",
    "    X.loc[df_sample[~df_sample.index.str.contains('cell0000')].index,:].to_csv(f'{s_date}_BM-Her2N75_SampledMeanIntensity_restore_div_arcsinh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save full dataframe, normalized\n",
    "if s_type == \"JE-TMA\":\n",
    "    if not os.path.exists('20201229_JE-TMA-41-43-62_restore_norm_div.csv'):\n",
    "        df_norm.to_csv('20201229_JE-TMA-41-43-62_restore_norm_div.csv')\n",
    "elif s_type == \"BM-Her2\":\n",
    "    if not os.path.exists('20201229_BM-Her2N75-15-17-18_restore_norm_div.csv'):\n",
    "        df_norm.to_csv('20201229_BM-Her2N75-15-17-18_restore_norm_div.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply RESTORE normalization: scaled\n",
    "\n",
    "All values below the background level were randomly set within a range\n",
    "between 0 and 0.02, while all values exceeding the background level (corresponding to\n",
    "signals) were linearly scaled to a range between 0.02 and 1. Thereby, influence of background\n",
    "variation on the subsequently applied single-cell analysis was eliminated, while foreground\n",
    "signals were stretched to a larger dynamic range. (https://www.biorxiv.org/content/10.1101/2020.09.30.321539v1.full.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply normalization: set below threshold to random value between 0 - 0.02\n",
    "df_norm = pd.DataFrame(index=df.index)\n",
    "for QUERY_MARKER in df_result.dropna().index.tolist():\n",
    "    for QUERY_SCENE in sorted(set(df.batch)):\n",
    "        i_thresh = df_result.loc[QUERY_MARKER,QUERY_SCENE]\n",
    "        ls_index_neg = df[(df.batch==QUERY_SCENE) & (df.loc[:,QUERY_MARKER] < i_thresh)].index\n",
    "        a_rand = np.random.random_sample((len(ls_index_neg),))*0.02\n",
    "        df_norm.loc[ls_index_neg,QUERY_MARKER] = a_rand\n",
    "        ls_index = df[(df.batch==QUERY_SCENE) & (df.loc[:,QUERY_MARKER] >= i_thresh)].index\n",
    "        df_norm.loc[ls_index,QUERY_MARKER] = sklearn.preprocessing.minmax_scale(df.loc[ls_index,QUERY_MARKER],feature_range=(0.02,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm['batch'] = [item.split('_')[0] for item in df_norm.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save full normalized dataframes\n",
    "if s_type == \"JE-TMA\":\n",
    "    if not os.path.exists('20201229_JE-TMA-41-43-62_restore_norm.csv'):\n",
    "        df_norm.to_csv('20201229_JE-TMA-41-43-62_restore_norm.csv')\n",
    "elif s_type == \"BM-Her2\":\n",
    "    if not os.path.exists('BM-Her2N75-15-17-18_restore_norm.csv'):\n",
    "        df_norm.to_csv('20201229_BM-Her2N75-15-17-18_restore_norm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the 3 normalized, sampled dataframes for kbet analysis\n",
    "s_trans='raw'\n",
    "s_date = '20201208'\n",
    "if s_type == \"JE-TMA\":\n",
    "    df_sample=pd.read_csv(f'{s_date}_JE-TMA-41-43-62_SampledMeanIntensity_{s_trans}.csv',index_col=0)\n",
    "elif s_type == \"BM-Her2\":\n",
    "    df_sample=pd.read_csv(f'{s_date}_BM-Her2N75_SampledMeanIntensity_{s_trans}.csv',index_col=0) # for Biomax TMA\n",
    "#save for kbet\n",
    "if s_type == \"JE-TMA\":\n",
    "    df_norm.loc[df_sample.index,:].to_csv(f'{s_date}_JE-TMA-41-43-62_SampledMeanIntensity_restore_scale.csv')\n",
    "elif s_type == \"BM-Her2\":\n",
    "    df_norm.loc[df_sample[~df_sample.index.str.contains('cell0000')].index,:].to_csv(f'{s_date}_BM-Her2N75_SampledMeanIntensity_restore_scale.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plot histograms\n",
    "#save\n",
    "df_norm['batch'] = [item.split('_')[0] for item in df_norm.index]\n",
    "#plot \n",
    "%matplotlib inline\n",
    "s_trans = 'scale'#'div'\n",
    "s_date = s_type #\"BM-Her2N75\"\n",
    "bins=50\n",
    "for s_marker in df_result.dropna().index.tolist():\n",
    "    print(s_marker)\n",
    "    fig,ax=plt.subplots(2,1,figsize = (5,5))\n",
    "    for idxs, s_batch in enumerate(sorted(set(df_norm.batch))):\n",
    "        df_batch = df_norm[(df_norm.batch==s_batch)].loc[:,s_marker] #+ 1 #set minimum to 1\n",
    "        if len(df_batch.dropna()) == 0:\n",
    "            continue\n",
    "        ax[0].hist(df.loc[df.index.str.contains(s_batch),s_marker],bins=bins,alpha=0.4, color=f'C{idxs}',label=s_batch)\n",
    "        ax[1].hist(df_batch,bins=bins,alpha=0.4, color=f'C{idxs}',label=s_batch)\n",
    "        ax[0].axvline(df_result.loc[s_marker,s_batch], c=f'C{idxs}',alpha=0.7,ls='--')\n",
    "        ax[0].set_yscale('log')\n",
    "        ax[1].set_yscale('log')\n",
    "        ax[0].set_title(f'{s_marker.split(\"_\")[0]}: Raw Data')\n",
    "        ax[1].set_title(f'{s_marker.split(\"_\")[0]}: Restore {s_trans}')\n",
    "        ax[0].legend()\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f'{rootdir}20201228/Different_Scaling_restore_{s_marker}_{s_trans}_{s_date}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-0.16",
   "language": "python",
   "name": "rapids-0.16"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
