{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Batch Normalization on tissues\n",
    "\n",
    "\n",
    "**Question:** How does combat batch normalization algorithms perform on adjacent section tissues stained with the same panel, when training with unmatched cores?\n",
    "\n",
    "**Samples:** \n",
    "- TMA: Purchased from biomax: https://www.biomax.us/tissue-arrays/Breast/BR1506\n",
    "- Adjacent Sections: BM-Her2N75-15, BM-Her2N75-17, BM-Her2N75-18 (section 16 skipped.)\n",
    "- Scenes: (i.e. TMA cores) \n",
    "  - 17: ER+/HER2+, immune rich. \n",
    "  - 49: ER+/HER2+\n",
    "  - 59: HER2+ immune rich\n",
    "\n",
    "**Method**: We performed combat normalization using unlike tissues as training set (different cores in training set and all cores in testing set). We visualized the resulting histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "import scanpy as sc\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import scale, minmax_scale, StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib as mpl\n",
    "mpl.rc('figure', max_open_warning = 0)\n",
    "os.chdir('//home/groups/graylab_share/OMERO.rdsStore/engje/Data/cmIF')\n",
    "from mplex_image import visualize as viz, process, preprocess, normalize\n",
    "np.random.seed(1202)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to correct directory\n",
    "#os.chdir('/home/groups/graylab_share/OMERO.rdsStore/engje/Data/cycIF_ValidationStudies/cycIF_Validation')\n",
    "codedir=os.getcwd()\n",
    "rootdir = f'{codedir}/Data/'\n",
    "datadir = f'{codedir}/Data/filtered_data'\n",
    "os.chdir(datadir)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df=pd.read_csv(f'20201229_BM-Her2N75-15-17-18_MeanIntensity.csv',index_col=0)\n",
    "df.rename({'slide':'batch'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importlib.reload(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(df_norm,df,s_train,s_tissue):\n",
    "    df_norm['batch'] = [item.split('_')[0] for item in df_norm.index]\n",
    "    bins=50\n",
    "    for s_marker in df_norm.columns[df_norm.dtypes=='float64']:\n",
    "        print(s_marker)\n",
    "        fig,ax=plt.subplots(2,1,figsize = (5,5))\n",
    "        for idxs, s_batch in enumerate(sorted(set(df_norm.batch))):\n",
    "            df_batch = df_norm[(df_norm.batch==s_batch)].loc[:,s_marker] \n",
    "            if len(df_batch.dropna()) == 0:\n",
    "                continue\n",
    "            ax[0].hist(df.loc[df.index.str.contains(s_batch),s_marker],bins=bins,alpha=0.4, color=f'C{idxs}',label=s_batch)\n",
    "            ax[1].hist(df_batch,bins=bins,alpha=0.4, color=f'C{idxs}',label=s_batch)\n",
    "            ax[0].set_yscale('log')\n",
    "            ax[1].set_yscale('log')\n",
    "            ax[0].set_title(f'{s_marker.split(\"_\")[0]}: Raw Data {s_train}')\n",
    "            ax[1].set_title(f'{s_marker.split(\"_\")[0]}: Combat')\n",
    "            ax[0].legend()\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(f'{rootdir}/20201228/Different_Scaling_combat_training_{s_train}_{s_marker}_{s_tissue}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all cores\n",
    "data = df.loc[:,df.dtypes=='float64'].T\n",
    "batch = df.batch\n",
    "gamma_star, delta_star = normalize.combat_fit(data, batch)\n",
    "#transform\n",
    "bayesdata = normalize.combat_transform(data,batch,gamma_star, delta_star)\n",
    "df_norm=bayesdata.T\n",
    "s_train='all'\n",
    "s_tissue = 'all'\n",
    "plot_histograms(df_norm,df,s_train,s_tissue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training combat with controls\n",
    "\n",
    "How sensitive is the combat algorithm to the inputs that determine the parameters?\n",
    "\n",
    "- Can different tissues in each batch be used to fit combat?\n",
    "- Can a limited set of tissues be used to fit combat?\n",
    "- Or, should the set of tissues used to fit combat be very similar to those it is applied to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lls_batch = [['BM-Her2N75-15', 'BM-Her2N75-17', 'BM-Her2N75-18'],\n",
    "            [ 'BM-Her2N75-17', 'BM-Her2N75-18','BM-Her2N75-15'],\n",
    "            [ 'BM-Her2N75-18','BM-Her2N75-15', 'BM-Her2N75-17']]\n",
    "ls_scene = sorted(set(df.scene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize with different training sets\n",
    "for idxx, ls_batch in enumerate(lls_batch):\n",
    "    data = pd.DataFrame()\n",
    "    for idx, s_batch in enumerate(ls_batch):\n",
    "        s_scene = ['scene017', 'scene049', 'scene059'][idx]\n",
    "        data = data.append(df.loc[((df.scene==s_scene)&(df.batch==s_batch)),:])   \n",
    "    #fit training set\n",
    "    gamma_star, delta_star = normalize.combat_fit(data.loc[:,data.dtypes=='float64'].T, data.batch)\n",
    "    #transform full data set\n",
    "    bayesdata = normalize.combat_transform(df.loc[:,df.dtypes=='float64'].T,df.batch,gamma_star, delta_star)\n",
    "    df_norm=bayesdata.T\n",
    "    s_train = \"_\".join([(item + ls_scene[idx]).split('-')[-1].replace('scene','s') for idx, item in enumerate(ls_batch)])\n",
    "    s_tissue = 'all'\n",
    "    plot_histograms(df_norm,data,s_train,s_tissue)\n",
    "    df_norm.sample(5400,random_state=3).to_csv(f'20201229-{idxx}_BM-Her2N75_SampledMeanIntensity_diff_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize with same training sets\n",
    "for idx, ls_batch in enumerate(lls_batch):\n",
    "    s_scene = ['scene017', 'scene049', 'scene059'][idx]\n",
    "    data = pd.DataFrame()\n",
    "    for s_batch in ls_batch:   \n",
    "        data = data.append(df.loc[((df.scene==s_scene)&(df.batch==s_batch)),:])   \n",
    "    #fit training set\n",
    "    gamma_star, delta_star = normalize.combat_fit(data.loc[:,data.dtypes=='float64'].T, data.batch)\n",
    "    #transform full data set\n",
    "    bayesdata = normalize.combat_transform(df.loc[:,df.dtypes=='float64'].T,df.batch,gamma_star, delta_star)\n",
    "    df_norm=bayesdata.T\n",
    "    s_train = \"_\".join([(item + s_scene).split('-')[-1].replace('scene','s') for idx, item in enumerate(ls_batch)])\n",
    "    s_tissue = 'all'\n",
    "    plot_histograms(df_norm,data,s_train,s_tissue)\n",
    "    df_norm.sample(5400,random_state=3).to_csv(f'20201229-{idx}_BM-Her2N75_SampledMeanIntensity_same_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize with sampled training sets\n",
    "ls_date = ['20201207','20201208','20201209']\n",
    "for idx, s_date in enumerate(ls_date):\n",
    "    data = pd.read_csv(f'{s_date}_BM-Her2N75-15-17-18_SampledMeanIntensity_raw.csv',index_col=0)\n",
    "    data['batch'] = [item.split('_')[0] for item in data.index]\n",
    "    #fit training set\n",
    "    gamma_star, delta_star = normalize.combat_fit(data.loc[:,data.dtypes=='float64'].T, data.batch)\n",
    "    #transform full data set\n",
    "    bayesdata = normalize.combat_transform(df.loc[:,df.dtypes=='float64'].T,df.batch,gamma_star, delta_star)\n",
    "    df_norm=bayesdata.T\n",
    "    s_train = s_date\n",
    "    s_tissue = 'all'\n",
    "    plot_histograms(df_norm,data,s_train,s_tissue)\n",
    "    df_norm.sample(5400,random_state=3).to_csv(f'20201229-{idx}_BM-Her2N75_SampledMeanIntensity_sampled_train.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESTORE methods: Results\n",
    "\n",
    "What is the best practice for restore normalization?\n",
    "\n",
    "- Global or local thresholds? - **Local slightly better but neither very good**\n",
    "- Raw data or arcsinh transformation? - **No difference**\n",
    "- Divide by threshold or scale values above threshold? - **Scale gives good normaliztion, but not as good as combat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(filterdir)\n",
    "df_file = pd.DataFrame(index=os.listdir())\n",
    "df_file = df_file[df_file.index.str.contains('BM-Her2N75-15-17-18_kbet_')]\n",
    "#ls_train = ['diff_train','raw', 'same_train', 'sampled_train','raw_combat']\n",
    "ls_method = ['raw', 'raw_combat', 'raw_regress_out', 'restore_local', 'restore_div','restore_div_arcsinh', 'restore_scale']#,'raw_restore_combat' 'raw_restore','raw_restore_regress_out',\n",
    "\n",
    "#add mean kbet\n",
    "for s_file in df_file.index:\n",
    "    df = pd.read_csv(s_file,index_col=0)\n",
    "    df_file.loc[s_file,'mean_kbet'] = df.loc['mean','kBET.observed']\n",
    "df_file['norm'] = [item.split('kbet_')[1].split('.csv')[0] for item in df_file.index]\n",
    "df_file = df_file[df_file.norm.isin(ls_method)]\n",
    "ls_index= df_file.groupby('norm').mean_kbet.mean().sort_values().index\n",
    "df_file.groupby('norm').mean_kbet.mean().sort_values()\n",
    "df_file['Norm'] = pd.Categorical(\n",
    "    df_file['norm'], \n",
    "    categories=ls_index.tolist(), \n",
    "    ordered=True\n",
    ")\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(figsize=(4.5,3))\n",
    "df_plot = df_file.sort_values('Norm')\n",
    "sns.lineplot(data=df_plot,x='norm',y='mean_kbet',ax=ax,err_style='bars')\n",
    "labels = [item.replace('raw_','').replace('_','\\n') for item in ls_index.tolist()]\n",
    "ax.set_xticks(range(len(df_file.groupby('norm').mean_kbet)))\n",
    "ax.set_xticklabels(labels,rotation=0)\n",
    "ax.set_ylabel('Rejection Rate')\n",
    "ax.set_xlabel('Normalization')\n",
    "ax.set_title('kBET Evaluation of Batch Correction II')\n",
    "fig.set_tight_layout(True)\n",
    "plt.tight_layout\n",
    "fig.savefig(f'{rootdir}/20201228/BatchEffectII.png',dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training combat with controls: Results\n",
    "\n",
    "How sensitive is the combat algorithm to the inputs that determine the parameters?\n",
    "\n",
    "- Can different tissues in each batch be used to fit combat? - **No, kbet rejection rate is near 1**\n",
    "- Can a limited set of tissues be used to fit combat? - **Varies, kbet rejection from 0.85 to 1, depending on training tissue**\n",
    "- Or, should the set of tissues used to fit combat be very similar to those it is applied to? - **Yes, lowest kbet rejection rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add mean kbet\n",
    "df_file = pd.DataFrame(index=os.listdir())\n",
    "df_file = df_file[df_file.index.str.contains('BM-Her2N75-15-17-18_kbet_')]\n",
    "ls_train = ['diff_train','raw', 'same_train', 'sampled_train','raw_combat']\n",
    "for s_file in df_file.index:\n",
    "    df = pd.read_csv(s_file,index_col=0)\n",
    "    df_file.loc[s_file,'mean_kbet'] = df.loc['mean','kBET.observed']\n",
    "df_file['norm'] = [item.split('kbet_')[1].split('.csv')[0] for item in df_file.index]\n",
    "df_file = df_file[df_file.norm.isin(ls_train)]\n",
    "ls_index= df_file.groupby('norm').mean_kbet.mean().sort_values().index\n",
    "df_file.groupby('norm').mean_kbet.mean().sort_values()\n",
    "df_file['Norm'] = pd.Categorical(\n",
    "    df_file['norm'], \n",
    "    categories=ls_index.tolist(), \n",
    "    ordered=True\n",
    ")\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(figsize=(4.5,3))\n",
    "df_plot = df_file.sort_values('Norm')\n",
    "sns.lineplot(data=df_plot,x='norm',y='mean_kbet',ax=ax,err_style='bars')\n",
    "labels = [item.replace('raw_','baseline_').replace('_','\\n') for item in ls_index.tolist()]\n",
    "ax.set_xticks(range(len(df_file.groupby('norm').mean_kbet)))\n",
    "ax.set_xticklabels(labels,rotation=0)\n",
    "ax.set_ylabel('Rejection Rate')\n",
    "ax.set_xlabel('Normalization')\n",
    "ax.set_title('kBET Evaluation of Combat Parameterization')\n",
    "fig.set_tight_layout(True)\n",
    "plt.tight_layout\n",
    "fig.savefig(f'{rootdir}/20201228/BatchEffect_CombatParam.png',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3",
   "language": "python",
   "name": "python3.8.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
